{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Phase Transitions - Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2FJBdMFCE8mk4N7SFnaa6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santacruzAI/MLPhasesOfMatter/blob/main/Machine_Learning_Phase_Transitions_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "!pip install numba\n",
        "from numba import jit"
      ],
      "metadata": {
        "id": "Inezb3UQhrCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e773a7-aa73-4bec-d058-cda6f3dbcf38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from numba) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Generation**"
      ],
      "metadata": {
        "id": "Ipw8nBYofz_o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mj43CC46fuHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da233ce-b3db-49c5-a565-d6aafc136026"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27000, 27000)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Generate random grids of 1s and -1s, making sure they are unbalanced. Then calculate the energy of the current state. \n",
        "#Then pick a random particle in the lattice, and flip its sign. When you flip the spin, you have to calculate the energy of this new state again. \n",
        "#If it is less than the current energy, switch curr state to new state. If greater, apply the probability e^-(beta)(Ev-E_mu) = e^-(beta)(J)(summation of the product between the \n",
        "#flipped particle and its neighbors).\n",
        "#Sample for many different temps\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.cm as cm\n",
        "@jit\n",
        "def get_energy(lattice):\n",
        "  en = 0\n",
        "  #Brute Neighbor Addition\n",
        "  for i in range(len(lattice)):\n",
        "    for j in range(len(lattice)):\n",
        "      if i>0:\n",
        "        en -= lattice[i][j]*lattice[i-1][j]\n",
        "      if i<len(lattice)-1:\n",
        "        en -= lattice[i][j]*lattice[i+1][j]\n",
        "      if j>0:\n",
        "        en -= lattice[i][j]*lattice[i][j-1]\n",
        "      if j<len(lattice)-1:\n",
        "        en -= lattice[i][j] * lattice[i][j+1]\n",
        "  return en\n",
        "\n",
        "grid_size = 40 #The grid size.\n",
        "starts = 10 #For each temperature. 10\n",
        "samples = 100 #The number of samples per start per temperature. 100\n",
        "temp_range = np.linspace(1,3.7,27) #The range of temperatures from 1 to 3.7\n",
        "therm_steps = 100 #100\n",
        "tempList = []\n",
        "sampleList = []\n",
        "imList = []\n",
        "k = (1.38064852)/(10**23)\n",
        "#b = 0.7 #This is our beta*J value. b = 1/kT\n",
        "count = 0\n",
        "total = 0\n",
        "loopCount = 0\n",
        "#fig = plt.figure(figsize=(grid_size,grid_size))\n",
        "for temp in temp_range:\n",
        "  b = 1/(k*temp)\n",
        "  for start in range(starts):\n",
        "    for sample in range(samples):\n",
        "      loopCount+=1\n",
        "      start_lat = np.array([[np.random.exponential() for a in range(grid_size)] for count2 in range(grid_size)])\n",
        "      lattice = np.zeros((grid_size,grid_size))\n",
        "      lattice[start_lat>=0.4] = 1.0\n",
        "      lattice[start_lat<0.4] = -1.0\n",
        "      if list(lattice.flatten()).count(1.)/(grid_size**2) > 0.5:\n",
        "        count+=1#To ensure largely unbalanced  \n",
        "        total += 1\n",
        "      else:\n",
        "        total += 1\n",
        "      enList = []\n",
        "      timeList = []\n",
        "      time = 0  \n",
        "      for therm_step in range(therm_steps):\n",
        "        curr_en = get_energy(lattice)\n",
        "        flip_x,flip_y = (random.randint(0,grid_size-1),random.randint(0,grid_size-1))\n",
        "        state_v = lattice.copy()\n",
        "        state_v[flip_x][flip_y] *=-1\n",
        "        v_en = get_energy(state_v)\n",
        "        p_uv = 1 if v_en<curr_en else np.exp(-b*(v_en - curr_en))\n",
        "        timeList.append(time)\n",
        "        time += 1\n",
        "        if np.random.random()<p_uv:\n",
        "          lattice = state_v.copy()\n",
        "        enList.append(get_energy(lattice))\n",
        "      sampleList.append(lattice)\n",
        "      #frames.append([plt.imshow(img[i], cmap=cm.Greys_r,animated=True)])\n",
        "      #plt.imshow(lattice)\n",
        "      tempList.append(temp)\n",
        "len(sampleList), loopCount\n",
        "#fig = plt.figure()\n",
        "#ani = animation.ArtistAnimation(fig, imList, interval=50, blit=True,\n",
        "#                                repeat_delay=1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.show()"
      ],
      "metadata": {
        "id": "9Nl2Qs4nvbXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization of Ising Model Simulation**"
      ],
      "metadata": {
        "id": "kydzXO8gSzAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoClip\n",
        "from moviepy.video.io.bindings import mplfig_to_npimage\n",
        "@jit\n",
        "def make_movie(sampleList):\n",
        "  fig, ax = plt.subplots() #What is subplots?\n",
        "  n = 120\n",
        "  animation = VideoClip(make_frame, duration = n)\n",
        "  animation.ipython_display(fps = len(sampleList)//n, loop = True, autoplay = True)\n",
        "\n",
        "def make_frame(t):\n",
        "    t = int(t/len(sampleList))\n",
        "    ax.clear()\n",
        "    ax.imshow(sampleList[t])\n",
        "    return mplfig_to_npimage(fig)\n",
        "  \n",
        "make_movie(sampleList)"
      ],
      "metadata": {
        "id": "lz8-fSjoFiuR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "49f5931b-1d35-4394-e686-c66c168ca439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2940928/45929032 bytes (6.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b5988352/45929032 bytes (13.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b8658944/45929032 bytes (18.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b10608640/45929032 bytes (23.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b13656064/45929032 bytes (29.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16343040/45929032 bytes (35.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20111360/45929032 bytes (43.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23699456/45929032 bytes (51.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27639808/45929032 bytes (60.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31555584/45929032 bytes (68.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35323904/45929032 bytes (76.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b38699008/45929032 bytes (84.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41426944/45929032 bytes (90.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44507136/45929032 bytes (96.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cb23179e276f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmplfig_to_npimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmake_movie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, make_frame, ismask, duration, has_constant_size)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_frame\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mismask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_constant_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_constant_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-124>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cb23179e276f>\u001b[0m in \u001b[0;36mmake_frame\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmplfig_to_npimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ax' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(timeList,enList)\n",
        "plt.title(\"Energy vs Algorithmic Time\")\n",
        "count/total"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DvhwA7S5iEN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preprocessing**"
      ],
      "metadata": {
        "id": "JgQor45rs5Ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_matrix = np.array([features.flatten() for features in sampleList]) #Flatten lattice\n",
        "np.random.shuffle(feature_matrix) #\n",
        "end = 2 * len(feature_matrix) // 5\n",
        "feature_train_matrix = feature_matrix[:-1*end]\n",
        "feature_test_matrix = feature_matrix[-1*end:]\n",
        "tempList2 = np.array([[temp] for temp in tempList])\n",
        "tempList2_train = tempList2[:-1*end]\n",
        "tempList2_test = tempList2[-1*end:]\n",
        "Tc = 2.27\n",
        "y_train = tempList2_train.copy()\n",
        "y_train[tempList2_train>=Tc] = 1\n",
        "y_train[tempList2_train<Tc] = 0\n",
        "y_test = tempList2_test.copy()\n",
        "y_test[tempList2_test>=Tc] = 1\n",
        "y_test[tempList2_test<Tc] = 0\n",
        "import pandas as pd\n",
        "csv_train = pd.DataFrame(feature_train_matrix)\n",
        "csv_train[\"y_train\"] = y_train\n",
        "csv_train = csv_train.to_csv(\"csv_train.csv\")\n",
        "csv_test = pd.DataFrame(feature_test_matrix)\n",
        "csv_test[\"y_test\"] = y_test\n",
        "csv_test = csv_test.to_csv(\"csv_test.csv\")\n",
        "#from google.colab import files\n",
        "#files.download(\"csv_train.csv\")\n",
        "#files.download(\"csv_test.csv\")"
      ],
      "metadata": {
        "id": "6ddVJ3Avs4r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feedforward Neural Network for Lattice Phase Transitions**"
      ],
      "metadata": {
        "id": "lgCnHuOXeUBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn #Super-class for PyTorch NNs\n",
        "from torch.nn import Sigmoid\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch import from_numpy\n",
        "class LinearModel(nn.Module): \n",
        "    def __init__(self): #Define struct\n",
        "        super(LinearModel, self).__init__()          \n",
        "        self.fc_1 = nn.Linear(grid_size*grid_size, 100)    \n",
        "        self.fc_2 = nn.Linear(100, 2)    \n",
        "            \n",
        "    def forward(self, X):    \n",
        "        #output = self.norm(X)\n",
        "        output = self.fc_1(X)\n",
        "        output = nn.Sigmoid()(output)\n",
        "        output = self.fc_2(output)\n",
        "        output = nn.Sigmoid()(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "IEZAUIpBJ5gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "model = LinearModel()\n",
        "model.train()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters())\n",
        "y_train = torch.from_numpy(y_train)\n",
        "y_train = y_train.type(torch.LongTensor)\n",
        "feature_train_matrix = torch.from_numpy(feature_train_matrix)#.type(torch.DoubleTensor)\n",
        "#print(np.shape(feature_train_matrix))\n",
        "acc_list = []\n",
        "ep_li = []\n",
        "for ep in range(EPOCHS):\n",
        "  acc = 0\n",
        "  ep_li.append(ep)\n",
        "  for i in range(len(y_train)):\n",
        "    feature = feature_train_matrix[i:i+1].type(torch.FloatTensor)\n",
        "    optimizer.zero_grad()\n",
        "    out = model(feature)\n",
        "    label = y_train[i][0].unsqueeze(0)\n",
        "    #print(label,out)\n",
        "    if(label.item()==out.argmax().item()):\n",
        "      acc+=1\n",
        "    loss = criterion(out,label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(\"EPOCH\",ep+1,\"loss: \",round(loss.item(),2))\n",
        "  print(\"Accuracy:\",acc/len(y_train))  \n",
        "  acc_list.append(acc/len(y_train))"
      ],
      "metadata": {
        "id": "qqarYm8KzcqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the plot of the accuracies vs epochs."
      ],
      "metadata": {
        "id": "LnezwOKLW8GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(ep_li, acc_list)"
      ],
      "metadata": {
        "id": "V1VxpwEGolnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we evaluate the accuracy of our PyTorch model on our test data."
      ],
      "metadata": {
        "id": "9wsW5zTZXDCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = torch.from_numpy(y_test)\n",
        "y_test = y_test.type(torch.LongTensor)\n",
        "feature_test_matrix = torch.from_numpy(feature_test_matrix)#.type(torch.DoubleTensor)\n",
        "model.eval()\n",
        "acc = 0\n",
        "for i in range(len(y_test)):\n",
        "    feature = feature_test_matrix[i:i+1].type(torch.FloatTensor)\n",
        "    out = model(feature)\n",
        "    label = y_test[i][0].unsqueeze(0)\n",
        "    #print(label,out)\n",
        "    if(label.item()==out.argmax().item()):\n",
        "      acc+=1\n",
        "    loss = criterion(out,label)\n",
        "#print(loss)\n",
        "print(acc/len(y_test))\n",
        "#csv_model = pd.DataFrame(model.state_dict())\n",
        "#csv_model = csv_model.to_csv(\"model1.csv\")\n",
        "#files.download(\"model1.csv\")\n",
        "#torch.save(model,\"./\")"
      ],
      "metadata": {
        "id": "ifTDctSOMeij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we save training and testing data in csvs as well as saving the PyTorch model."
      ],
      "metadata": {
        "id": "jjpLnS2wXLdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "#files.download(\"csv_train.csv\")\n",
        "#files.download(\"csv_test.csv\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#torch.save(model.state_dict(), '/content/gdrive/My Drive/SCAI ML Phases of Matter Implementation/model1.994.pth')\n",
        "torch.save(model.state_dict(), '/content/gdrive/My Drive/SCAI ML Phases of Matter Implementation/model1.989.pth')"
      ],
      "metadata": {
        "id": "bnJmD5Mze6W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we generate Triangular Lattices to evaluate our model against."
      ],
      "metadata": {
        "id": "BH3useq_lM1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we generate a hexagonal filter."
      ],
      "metadata": {
        "id": "N1k8eoJiL4eI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "grid_size = 40\n",
        "grid = np.zeros((grid_size, grid_size)) > np.ones((grid_size, grid_size))\n",
        "grid_length = grid_size - grid_size // 3\n",
        "for i in range(grid_length//2):\n",
        "  for j in range((grid_size-1)//3 - i,2*(grid_size-1)//3 + i):\n",
        "    grid[i][j] = True\n",
        "for i in range(grid_length//2,grid_length):\n",
        "  k = i - grid_length//2\n",
        "  init_left = (grid_size - 1)//3 - grid_length//2 \n",
        "  init_right = 2*(grid_size - 1)//3 + grid_length//2\n",
        "  for j in range(init_left+ k,init_right - k):\n",
        "    grid[i][j] = True\n",
        "plt.figure(figsize=(grid_size,grid_size))\n",
        "plt.imshow(grid)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6-McudEoth4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we generate triangular lattices, in the sense that it has a Triangular Hamiltonian. But we still generate square spins."
      ],
      "metadata": {
        "id": "V3nDjSivXmqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload() #Here, we reload our PyTorch model so that we don't need to retrain it each time."
      ],
      "metadata": {
        "id": "hqSTWwB9ZMQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def get_energy(lattice):\n",
        "  en = 0\n",
        "  #Hexagonal Neighbor Addition\n",
        "  for i in range(len(lattice)):\n",
        "    for j in range(len(lattice[i])):\n",
        "      if(i>1 and j>2):\n",
        "        en += lattice[i][j] * lattice[i-1][j-1] * lattice[i][j-2]\n",
        "      if (i<len(lattice)-1 and j>2):\n",
        "        en += lattice[i][j] * lattice[i][j-2] * lattice[i+1][j-1]\n",
        "      if (i<len(lattice)-2 and j>1 and j<len(lattice)-1):\n",
        "        en += lattice[i][j] * lattice[i+1][j+1] * lattice[i+1][j-1]\n",
        "      if (i<len(lattice) - 2 and j<len(lattice) - 2):\n",
        "        en += lattice[i][j] * lattice[i+1][j+1] * lattice[i][j+2]\n",
        "      if (i>1 and j<len(lattice) - 2):\n",
        "        en += lattice[i][j] * lattice[i][j+2] * lattice[i-1][j+1]\n",
        "      if (i>1 and j > 1 and j<len(lattice) - 1):\n",
        "        en += lattice[i][j] * lattice[i-1][j+1] * lattice[i-1][j-1]\n",
        "  return en\n",
        "\n",
        "grid_size = 40\n",
        "starts = 10 #For each temperature. 10\n",
        "samples = 100 #The number of samples per start per temperature. 100\n",
        "temp_range = np.linspace(1,3.7,27) #The range of temperatures from 1 to 3.7\n",
        "therm_steps = 100 #100\n",
        "tempList = []\n",
        "sampleList = []\n",
        "k = (1.38064852)/(10**23)\n",
        "#b = 0.7 #This is our beta*J value. b = 1/kT\n",
        "count = 0\n",
        "total = 0\n",
        "loopCount = 0\n",
        "for temp in temp_range:\n",
        "  b = 1/(k*temp)\n",
        "  for start in range(starts):\n",
        "    for sample in range(samples):\n",
        "      loopCount+=1\n",
        "      start_lat = np.array([[np.random.exponential() for a in range(grid_size)] for count2 in range(grid_size)])\n",
        "      lattice = np.zeros((grid_size,grid_size))\n",
        "      lattice[start_lat>=0.4] = 1.0\n",
        "      lattice[start_lat<0.4] = -1.0\n",
        "      if list(lattice.flatten()).count(1.)/(grid_size**2) > 0.5:\n",
        "        count+=1#To ensure largely unbalanced  \n",
        "        total += 1\n",
        "      else:\n",
        "        total += 1\n",
        "      enList = []\n",
        "      timeList = []\n",
        "      time = 0  \n",
        "      for therm_step in range(therm_steps):\n",
        "        curr_en = get_energy(lattice)\n",
        "        flip_x,flip_y = (random.randint(0,grid_size-1),random.randint(0,grid_size-1))\n",
        "        state_v = lattice.copy()\n",
        "        state_v[flip_x][flip_y] *=-1\n",
        "        v_en = get_energy(state_v)\n",
        "        p_uv = 1 if v_en<curr_en else np.exp(-b*(v_en - curr_en))\n",
        "        timeList.append(time)\n",
        "        time += 1\n",
        "        if np.random.random()<p_uv:\n",
        "          lattice = state_v.copy()\n",
        "        enList.append(get_energy(lattice))\n",
        "      sampleList.append(lattice)\n",
        "      tempList.append(temp)"
      ],
      "metadata": {
        "id": "IszWE5TvXpF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleList[0]"
      ],
      "metadata": {
        "id": "FUheNJghYaAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(timeList,enList)\n",
        "plt.title(\"Energy vs Algorithmic Time\")\n",
        "count/total"
      ],
      "metadata": {
        "id": "vTFrjTlmYdOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_matrix = np.array([features.flatten() for features in sampleList]) #Flatten lattice\n",
        "np.random.shuffle(feature_matrix) #\n",
        "end = 2 * len(feature_matrix) // 5\n",
        "feature_train_matrix = feature_matrix[:-1*end]\n",
        "feature_test_matrix = feature_matrix[-1*end:]\n",
        "tempList2 = np.array([[temp] for temp in tempList])\n",
        "tempList2_train = tempList2[:-1*end]\n",
        "tempList2_test = tempList2[-1*end:]\n",
        "Tc = 2.27\n",
        "y_train = tempList2_train.copy()\n",
        "y_train[tempList2_train>=Tc] = 1\n",
        "y_train[tempList2_train<Tc] = 0\n",
        "y_test = tempList2_test.copy()\n",
        "y_test[tempList2_test>=Tc] = 1\n",
        "y_test[tempList2_test<Tc] = 0"
      ],
      "metadata": {
        "id": "DMTODh6oYfrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/gdrive/My Drive/SCAI ML Phases of Matter Implementation/model1.989.pth\"\n",
        "# Load\n",
        "model = LinearModel()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "y_test = torch.from_numpy(y_test)\n",
        "y_test = y_test.type(torch.LongTensor)\n",
        "feature_test_matrix = torch.from_numpy(feature_test_matrix)#.type(torch.DoubleTensor)\n",
        "model.eval()\n",
        "acc = 0\n",
        "for i in range(len(y_test)):\n",
        "    feature = feature_test_matrix[i:i+1].type(torch.FloatTensor)\n",
        "    out = model(feature)\n",
        "    label = y_test[i][0].unsqueeze(0)\n",
        "    #print(label,out)\n",
        "    if(label.item()==out.argmax().item()):\n",
        "      acc+=1\n",
        "    #loss = criterion(out,label)\n",
        "#print(loss)\n",
        "print(acc/len(y_test))"
      ],
      "metadata": {
        "id": "7C8z5lSlYjj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we generate Triangular Lattices in a hexagonal shape, but allow to try to flip the zero spins. (Zero spins just represent nothing; we are using them to outline the hexagons)"
      ],
      "metadata": {
        "id": "Xd5Ho1EuX0kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def get_energy(lattice):\n",
        "  en = 0\n",
        "  #Hexagonal Neighbor Addition\n",
        "  for i in range(len(lattice)):\n",
        "    for j in range(len(lattice[i])):\n",
        "      if(i>1 and j>2):\n",
        "        en += lattice[i][j] * lattice[i-1][j-1] * lattice[i][j-2]\n",
        "      elif (i<len(lattice)-1 and j>2):\n",
        "        en += lattice[i][j] * lattice[i][j-2] * lattice[i+1][j-1]\n",
        "      elif (i<len(lattice)-2 and j>1 and j<len(lattice)-1):\n",
        "        en += lattice[i][j] * lattice[i+1][j+1] * lattice[i+1][j-1]\n",
        "      elif (i<len(lattice) - 2 and j<len(lattice) - 2):\n",
        "        en += lattice[i][j] * lattice[i+1][j+1] * lattice[i][j+2]\n",
        "      elif (i>1 and j<len(lattice) - 2):\n",
        "        en += lattice[i][j] * lattice[i][j+2] * lattice[i-1][j+1]\n",
        "      elif (i>1 and j > 1 and j<len(lattice) - 1):\n",
        "        en += lattice[i][j] * lattice[i-1][j+1] * lattice[i-1][j-1]\n",
        "  return en\n",
        "\n",
        "starts = 10 #For each temperature. 10\n",
        "samples = 100 #The number of samples per start per temperature. 100\n",
        "temp_range = np.linspace(1,3.7,27) #The range of temperatures from 1 to 3.7\n",
        "therm_steps = 100 #100\n",
        "tempList = []\n",
        "sampleList = []\n",
        "k = (1.38064852)/(10**23)\n",
        "#b = 0.7 #This is our beta*J value. b = 1/kT\n",
        "count = 0\n",
        "total = 0\n",
        "loopCount = 0\n",
        "for temp in temp_range:\n",
        "  b = 1/(k*temp)\n",
        "  for start in range(starts):\n",
        "    for sample in range(samples):\n",
        "      loopCount+=1\n",
        "      start_lat = np.array([[np.random.exponential() for a in range(grid_size)] for count2 in range(grid_size)])\n",
        "      lattice = np.zeros((grid_size,grid_size))\n",
        "      lattice[start_lat>=0.4] = 1.0\n",
        "      lattice[start_lat<0.4] = -1.0\n",
        "      for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "          if not grid[i][j]:\n",
        "            lattice[i][j] = 0\n",
        "      if list(lattice.flatten()).count(1.)/(grid_size**2) > 0.5:\n",
        "        count+=1#To ensure largely unbalanced  \n",
        "        total += 1\n",
        "      else:\n",
        "        total += 1\n",
        "      enList = []\n",
        "      timeList = []\n",
        "      time = 0  \n",
        "      for therm_step in range(therm_steps):\n",
        "        curr_en = get_energy(lattice)\n",
        "        flip_x,flip_y = (random.randint(0,grid_size-1),random.randint(0,grid_size-1))\n",
        "        state_v = lattice.copy()\n",
        "        state_v[flip_x][flip_y] *=-1\n",
        "        v_en = get_energy(state_v)\n",
        "        p_uv = 1 if v_en<curr_en else np.exp(-b*(v_en - curr_en))\n",
        "        timeList.append(time)\n",
        "        time += 1\n",
        "        if np.random.random()<p_uv:\n",
        "          lattice = state_v.copy()\n",
        "        enList.append(get_energy(lattice))\n",
        "      sampleList.append(lattice)\n",
        "      tempList.append(temp)"
      ],
      "metadata": {
        "id": "b_oXpENVYDhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleList[0]"
      ],
      "metadata": {
        "id": "-zxX67DMYmWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(timeList,enList)\n",
        "plt.title(\"Energy vs Algorithmic Time\")\n",
        "count/total"
      ],
      "metadata": {
        "id": "P3N_jXUHYojX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_matrix = np.array([features.flatten() for features in sampleList]) #Flatten lattice\n",
        "np.random.shuffle(feature_matrix) #\n",
        "end = 2 * len(feature_matrix) // 5\n",
        "feature_train_matrix = feature_matrix[:-1*end]\n",
        "feature_test_matrix = feature_matrix[-1*end:]\n",
        "tempList2 = np.array([[temp] for temp in tempList])\n",
        "tempList2_train = tempList2[:-1*end]\n",
        "tempList2_test = tempList2[-1*end:]\n",
        "Tc = 2.27\n",
        "y_train = tempList2_train.copy()\n",
        "y_train[tempList2_train>=Tc] = 1\n",
        "y_train[tempList2_train<Tc] = 0\n",
        "y_test = tempList2_test.copy()\n",
        "y_test[tempList2_test>=Tc] = 1\n",
        "y_test[tempList2_test<Tc] = 0"
      ],
      "metadata": {
        "id": "jEprwjIeYrkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/gdrive/My Drive/SCAI ML Phases of Matter Implementation/model1.989.pth\"\n",
        "# Load\n",
        "model = LinearModel()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "y_test = torch.from_numpy(y_test)\n",
        "y_test = y_test.type(torch.LongTensor)\n",
        "feature_test_matrix = torch.from_numpy(feature_test_matrix)#.type(torch.DoubleTensor)\n",
        "model.eval()\n",
        "acc = 0\n",
        "for i in range(len(y_test)):\n",
        "    feature = feature_test_matrix[i:i+1].type(torch.FloatTensor)\n",
        "    out = model(feature)\n",
        "    label = y_test[i][0].unsqueeze(0)\n",
        "    #print(label,out)\n",
        "    if(label.item()==out.argmax().item()):\n",
        "      acc+=1\n",
        "    #loss = criterion(out,label)\n",
        "#print(loss)\n",
        "print(acc/len(y_test))"
      ],
      "metadata": {
        "id": "xG4QameOYuAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we generate Triangular Lattices, in a hexagonal shape. (The other elements in the lattice are 0s, no spins)"
      ],
      "metadata": {
        "id": "V0wRWvqSTx6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def get_energy(lattice):\n",
        "  en = 0\n",
        "  #Hexagonal Neighbor Addition\n",
        "  for i in range(len(lattice)):\n",
        "    for j in range(len(lattice[i])):\n",
        "      if(i>1 and j>2):s\n",
        "        en += lattice[i][j] * lattice[i-1][j-1] * lattice[i][j-2]\n",
        "      if (i<len(lattice)-1 and j>2):\n",
        "        en += lattice[i][j] * lattice[i][j-2] * lattice[i+1][j-1]\n",
        "      if (i<len(lattice)-2 and j>1 and j<len(lattice)-1):\n",
        "        en += lattice[i][j] * lattice[i+1][j+1] * lattice[i+1][j-1]\n",
        "      if (i<len(lattice) - 2 and j<len(lattice) - 2):\n",
        "        en += lattice[i][j] * lattice[i+1][j+1] * lattice[i][j+2]\n",
        "      if (i>1 and j<len(lattice) - 2):\n",
        "        en += lattice[i][j] * lattice[i][j+2] * lattice[i-1][j+1]\n",
        "      if (i>1 and j > 1 and j<len(lattice) - 1):\n",
        "        en += lattice[i][j] * lattice[i-1][j+1] * lattice[i-1][j-1]\n",
        "  return en\n",
        "\n",
        "starts = 10 #For each temperature. 10\n",
        "samples = 100 #The number of samples per start per temperature. 100\n",
        "temp_range = np.linspace(1,3.7,27) #The range of temperatures from 1 to 3.7\n",
        "therm_steps = 100 #100\n",
        "tempList = []\n",
        "sampleList = []\n",
        "k = (1.38064852)/(10**23)\n",
        "#b = 0.7 #This is our beta*J value. b = 1/kT\n",
        "count = 0\n",
        "total = 0\n",
        "loopCount = 0\n",
        "for temp in temp_range:\n",
        "  b = 1/(k*temp)\n",
        "  for start in range(starts):\n",
        "    for sample in range(samples):\n",
        "      loopCount+=1\n",
        "      start_lat = np.array([[np.random.exponential() for a in range(grid_size)] for count2 in range(grid_size)])\n",
        "      lattice = np.zeros((grid_size,grid_size))\n",
        "      lattice[start_lat>=0.4] = 1.0\n",
        "      lattice[start_lat<0.4] = -1.0\n",
        "      for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "          if not grid[i][j]:\n",
        "            lattice[i][j] = 0\n",
        "      if list(lattice.flatten()).count(1.)/(grid_size**2) > 0.5:\n",
        "        count+=1#To ensure largely unbalanced  \n",
        "        total += 1\n",
        "      else:\n",
        "        total += 1\n",
        "      enList = []\n",
        "      timeList = []\n",
        "      time = 0  \n",
        "      for therm_step in range(therm_steps):\n",
        "        curr_en = get_energy(lattice)\n",
        "        flip_x,flip_y = (random.randint(0,grid_size-1),random.randint(0,grid_size-1))\n",
        "        while lattice[flip_x][flip_y]==0:\n",
        "          flip_x,flip_y = (random.randint(0,grid_size-1),random.randint(0,grid_size-1))\n",
        "        state_v = lattice.copy()\n",
        "        state_v[flip_x][flip_y] *=-1\n",
        "        v_en = get_energy(state_v)\n",
        "        p_uv = 1 if v_en<curr_en else np.exp(-b*(v_en - curr_en))\n",
        "        timeList.append(time)\n",
        "        time += 1\n",
        "        if np.random.random()<p_uv:\n",
        "          lattice = state_v.copy()\n",
        "        enList.append(get_energy(lattice))\n",
        "      sampleList.append(lattice)\n",
        "      tempList.append(temp)"
      ],
      "metadata": {
        "id": "uPklBpLI_Gc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleList[0]"
      ],
      "metadata": {
        "id": "9hDjnnK1FzXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(timeList,enList)\n",
        "plt.title(\"Energy vs Algorithmic Time\")\n",
        "count/total"
      ],
      "metadata": {
        "id": "UhYFYRI7G7KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_matrix = np.array([features.flatten() for features in sampleList]) #Flatten lattice\n",
        "np.random.shuffle(feature_matrix) #\n",
        "end = 2 * len(feature_matrix) // 5\n",
        "feature_train_matrix = feature_matrix[:-1*end]\n",
        "feature_test_matrix = feature_matrix[-1*end:]\n",
        "tempList2 = np.array([[temp] for temp in tempList])\n",
        "tempList2_train = tempList2[:-1*end]\n",
        "tempList2_test = tempList2[-1*end:]\n",
        "Tc = 2.27\n",
        "y_train = tempList2_train.copy()\n",
        "y_train[tempList2_train>=Tc] = 1\n",
        "y_train[tempList2_train<Tc] = 0\n",
        "y_test = tempList2_test.copy()\n",
        "y_test[tempList2_test>=Tc] = 1\n",
        "y_test[tempList2_test<Tc] = 0"
      ],
      "metadata": {
        "id": "_TnbJvQoHBKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/gdrive/My Drive/SCAI ML Phases of Matter Implementation/model1.989.pth\"\n",
        "# Load\n",
        "model = LinearModel()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "y_test = torch.from_numpy(y_test)\n",
        "y_test = y_test.type(torch.LongTensor)\n",
        "feature_test_matrix = torch.from_numpy(feature_test_matrix)#.type(torch.DoubleTensor)\n",
        "model.eval()\n",
        "acc = 0\n",
        "for i in range(len(y_test)):\n",
        "    feature = feature_test_matrix[i:i+1].type(torch.FloatTensor)\n",
        "    out = model(feature)\n",
        "    label = y_test[i][0].unsqueeze(0)\n",
        "    #print(label,out)\n",
        "    if(label.item()==out.argmax().item()):\n",
        "      acc+=1\n",
        "    #loss = criterion(out,label)\n",
        "#print(loss)\n",
        "print(acc/len(y_test))"
      ],
      "metadata": {
        "id": "SeUI2fLkIHcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jtgX819ZtznX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}